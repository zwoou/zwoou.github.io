# 多线程

[TOC]

## 1. 基本概念

1. 进程：是一个执行中的程序，每一个进程执行都有一个执行顺序，该顺序是一个执行路径，或者叫一个控制单元。
进程：一个计算机程序的运行实例，包含了需要执行的指令；有自己的独立地址空间，包含程序内容和数据；
不同进程的地址空间是互相隔离的；进程拥有各种资源和状态信息，包括打开的文件、子进程和信号处理。
2. 线程：表示程序的执行流程，是CPU调度执行的基本单位；线程有自己的程序计数器、寄存器、堆栈和帧,并且能够访问共享的内存变量。
    同一进程中的线程共用相同的地址空间，同时共享进进程锁拥有的内存和其他资源。
3. 新建线程

- 通过继承Thread类
- 通过实现runable接口
- 通过实现callable接口

## 2. 线程优先级

java 中的线程优先级的范围是1～10，默认的优先级是5。10极最高。
`setPriority`方法设置

## 3. 线程的状态

6个状态定义:java.long.Thread.State

| 状态名称     | 说明         |
| ------------ | ------------ |
| NEW          | 初始状态     |
| RUNNABLE     | 运行状态     |
| BLOCKED      | 阻塞状态     |
| WAITING      | 等待状态     |
| TIME_WAITING | 超时等待状态 |
| TERMINATED   | 终止状态     |



![线程状态](https://gitee.com/zwoou/picgo/raw/master/pic/20210304214921.png)

## 4. Daemon线程

## 5. 启动和终止线程

终止线程的三种方式

1. 使用标志位终止线程
2. 使用stop()方法强制终止线程,但是不推荐此方法,已经被弃用
3. 使用interrupt方法中断线程

## 6. 线程间通信

### 6.1 线程协作API  

生产者/消费者模式

- API-被弃用的suspend和resume. 容易死锁  
- 等待/通知机制 wait/notify  
方法wait()的作用是使当前执行代码的线程进行等待,直到接到通知或被中断为止.
在调用wait()方法之前,线程必须获得该对象的对象级锁,没有则抛出IllealMonitorStateExpection  
方法notify()也必须在同步方法或同步代码块中调用.  
注意:wait会自动释放锁,但是对顺序有要求.
- park/unpark机制  
线程调用park则等待"许可",unpack方法为指定线程提供"许可(permit)"  
不要求park和unpack方法的调用顺序.  

注意:伪唤醒 ,用while循环条件判断

### 6.2 通过管道进行线程间通信

管道流(pipeStrem)是一种特殊的流,用于在不同线程间直接传送数据.一个线程发送数据到输出管道,另一个线程从输入管道读数据.

在JDK中使用四个类来实现  

1. PipedInputStream和PipedOutputStream
2. PipedReader和PipedWriter  

### 6.3 Thread.join()的使用

方法join()的作用是等待线程对象销毁.  
方法join(long)中的参数是设定等待的时间.  

### 6.4 文件共享

### 6.5 网络共享

### 6.6 变量共享


如图，synchronized可以用在**方法**上也可以使用在**代码块**中，其中方法是实例方法和静态方法分别锁的是该类的实例对象和该类的对象。而使用在代码块中也可以分为三种，具体的可以看上面的表格。这里的需要注意的是：**如果锁的是类对象的话，尽管new多个实例对象，但他们仍然是属于同一个类依然会被锁住，即线程之间保证同步关系**。

- 对象锁（monitor）机制

  **每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一**。

  

### 6.5 ThreadLocal的使用

线程封闭概念 
和栈封闭 

## 7. 线程应用实例



### 7.1 等待超时模式



### 7.2 数据库连接池







volatile 的定义
java编程允许线程访问共享变量，为了确保共享变量能被准确和一致性的更新，线程应该确保通过排他锁单独获得这个变量。
synchronized 的实现原理与应用
java中每一个对象都可以作为锁。具体表现：

    1. 对于普通同步方法，锁是当前实例对象。
        2. 对于静态同步方法，锁是当前类的Class对象。
        3. 对于同步方法块，锁是Synchonized括号里配置的对象。
锁的升级
级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态。

2. Java标准库提供了进程和线程相关的API，进程主要包括表示进程的java.lang.Process类和创建进程的java.lang.ProcessBuilder类；
3. 线程间的可见性：一个线程对进程中共享的数据的修改，是否对另一个线程可见
可见性问题：
    a. CPU采用时间片轮转等不同算法来对线程进行调度
    b. cpu缓存
    c. 指令顺序重排。
4. 
死锁： 线程间互相等待对方释放锁。
**避免死锁常用方法**
- 避免一个线程同时获取多个锁
- 避免一个线程在锁内同时占用多个资源，尽量保证一个线程占用一个资源。
- 尝试使用定时锁，使用lock.tryLock(timeout)来替代内部锁机制。
- 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败情况。

**Java内存模型（Java Memory Model）**
屏蔽了CPU缓存等细节，只关注主存中的共享变量；关注对象的实例域、静态域和数组元素；关注线程间的动作。

1. volatile关键字用来对共享变量的访问进行同步，上一次写入操作的结果对下一次读取操作是肯定可见的。（在写入volatile变量值之后，CPU缓存中的内容会被写回内存；在读取volatile变量时，CPU缓存中的对应内容会被置为失效，重新从主存中进行读取），volatile不使用锁，性能优于synchronized关键词。
2. final关键词
final关键词声明的域的值只能被初始化一次，一般在构造方法中初始化。。（在多线程开发中，final域通常用来实现不可变对象）
当对象中的共享变量的值不可能发生变化时，在多线程中也就不需要同步机制来进行处理，故在多线程开发中应尽可能使用不可变对象。
另外，在代码执行时，final域的值可以被保存在寄存器中，而不用从主存中频繁重新读取。

## 8. 并发编程有哪些缺点

### 1. 频繁的上下文切换

通常减少上下文切换可以采用无锁并发编程,CAS算法,使用最少线程和使用协程

- 无锁并发编程：可以参照concurrentHashMap锁分段的思想，不同的线程处理不同段的数据，这样在多线程竞争的条件下，可以减少上下文切换的时间。

- CAS算法，利用Atomic下使用CAS算法来更新数据，使用了乐观锁，可以有效的减少一部分不必要的锁竞争带来的上下文切换

- 使用最少线程：避免创建不需要的线程，比如任务很少，但是创建了很多的线程，这样会造成大量的线程都处于等待状态

- 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换

### 2. 线程安全

## 9. 线程池应用及原理

### 9.1 概念

1. 线程池管理器
2. 工作线程
3. 任务接口
4. 任务队列




线程池的实现类ThreadPoolExecutor,其构造方法有4种

- **corePoolSize**(必须): 核心线程数,默认情况下,核心线程会一直存活.但是当将allowCoreThreadTimeout设置为true时,核心线程也会超时回收.  

- maximumPoolSize(必须):线程池所能容纳的最大线程数。当活跃线程数达到该数值后，后续的新任务将会阻塞。  

- keepAliveTime(必须):线程闲置超时时长.如果超过该时长,非核心线程就会被回收.如果将allowCoreThreadTimeout设置为true时,核心线程也会超时回收.  
- unit（必需）：指定keepAliveTime参数的时间单位。常用的有：TimeUnit.MILLISECONDS（毫秒）、TimeUnit.SECONDS（秒）、TimeUnit.MINUTES（分）。
- workQueue（必需）：任务队列。通过线程池的execute()方法提交的Runnable对象将存储在该参数中。其采用阻塞队列实现。
- threadFactory（可选）：线程工厂。用于指定为线程池创建新线程的方式。
- handler（可选）：拒绝策略。当达到最大线程数时需要执行的饱和策略。




## synchronized优化


## CAS操作

CAS比较交换的过程可以通俗的理解为CAS(V,O,N)，包含三个值分别为：**V 内存地址存放的实际值；O 预期的值（旧值）；N 更新的新值**。

### CAS的问题

1. ABA问题

   因为CAS会检查旧值有没有变化，这里存在这样一个有意思的问题。比如一个旧值A变为了成B，然后再变成A，刚好在做CAS时检查发现旧值并没有变化依然为A，但是实际上的确发生了变化。解决方案可以沿袭数据库中常用的乐观锁方式，添加一个版本号可以解决。原来的变化路径A->B->A就变成了1A->2B->3C。java这么优秀的语言，当然在java 1.5后的atomic包中提供了AtomicStampedReference来解决ABA问题，解决思路就是这样的

2. 自旋时间过长
   使用CAS时非阻塞同步，也就是说不会将线程挂起，会自旋（无非就是一个死循环）进行下一次尝试，如果这里自旋时间过长对性能是很大的消耗。如果JVM能支持处理器提供的pause指令，那么在效率上会有一定的提升。

3.  **只能保证一个共享变量的原子操作**

当对一个共享变量执行操作时CAS能保证其原子性，如果对多个共享变量进行操作,CAS就不能保证其原子性。有一个解决方案是利用对象整合多个共享变量，即一个类中的成员变量就是这几个共享变量。然后将这个对象做CAS操作就可以保证其原子性。atomic中提供了AtomicReference来保证引用对象之间的原子性


## Java对象头

Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：**无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态**，这几个状态会随着竞争情况逐渐升级。**锁可以升级但不能降级**，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。对象的MarkWord变化为下图

## java内存屏障的原理与应用（jmm）

1. 什么是java内存屏障(Memory Barrier)?
内存屏障是一个CPU指令.基本上他是这样一个指令:a)确保一些特定操作执行的顺序.b)影响一些数据的可见性(可能是某些指令执行后的结果).
编译器和CPU可以在保证输出结果一样的情况下对指令重排序，使性能得到优化。插入一个内存屏障，相当于告诉CPU和编译器先于这个命令的必须先执行，后于这个命令的必须后执行。内存屏障另一个作用是强制更新一次不同CPU的缓存。例如，一个写屏障会把这个屏障前写入的数据刷新到缓存，这样任何试图读取该数据的线程将得到最新值，而不用考虑到底是被哪个cpu核心或者哪颗CPU执行的。

2. 为什么需要内存屏障?
我们知道，在多CPU（核）场景下，为了充分利用CPU，会通过流水线将指令并行进行。为了能并行执行，又需要将指令进行重排序以便进行并行执行，那么问题来了，那些指令不是在所有场景下都能进行重排，除了本身的一些规则（如Happens Before 规则）之外，我们还需要确保多CPU的高速缓存中的数据与内存保持一致性, 不能确保内存与CPU缓存数据一致性的指令也不能重排，内存屏障正是通过阻止屏障两边的指令重排序来避免编译器和硬件的不正确优化而提出的一种解决办法。
1.3 硬件层的内存屏障
Intel硬件提供了一系列的内存屏障，主要有： 
1. lfence，是一种Load Barrier 读屏障 
2. sfence, 是一种Store Barrier 写屏障 
3. mfence, 是一种全能型的屏障，具备ifence和sfence的能力 
4. Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。它后面可以跟ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG等指令。


1.4 内存屏障的主要类型
不同硬件实现内存屏障的方式不同，Java内存模型屏蔽了这种底层硬件平台的差异，由JVM来为不同的平台生成相应的机器码.
Java内存屏障主要有Load和Store两类。
对Load Barrier来说，在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据

对Store Barrier来说，在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存

对于Load和Store，在实际使用中，又分为以下四种：

LoadLoad 屏障
序列：Load1,Loadload,Load2
确保Load1所要读入的数据能够在被Load2和后续的load指令访问前读入。通常能执行预加载指令或/和支持乱序处理的处理器中需要显式声明Loadload屏障，因为在这些处理器中正在等待的加载指令能够绕过正在等待存储的指令。 而对于总是能保证处理顺序的处理器上，设置该屏障相当于无操作。

StoreStore 屏障 
序列：Store1，StoreStore，Store2
确保Store1的数据在Store2以及后续Store指令操作相关数据之前对其它处理器可见（例如向主存刷新数据）。通常情况下，如果处理器不能保证从写缓冲或/和缓存向其它处理器和主存中按顺序刷新数据，那么它需要使用StoreStore屏障。

LoadStore 屏障 
序列： Load1; LoadStore; Store2
确保Load1的数据在Store2和后续Store指令被刷新之前读取。在等待Store指令可以越过loads指令的乱序处理器上需要使用LoadStore屏障。

StoreLoad 屏障 
序列: Store1; StoreLoad; Load2 
确保Store1的数据在被Load2和后续的Load指令读取之前对其他处理器可见。StoreLoad屏障可以防止一个后续的load指令 不正确的使用了Store1的数据，而不是另一个处理器在相同内存位置写入一个新数据。正因为如此，所以在下面所讨论的处理器为了在屏障前读取同样内存位置存过的数据，必须使用一个StoreLoad屏障将存储指令和后续的加载指令分开。Storeload屏障在几乎所有的现代多处理器中都需要使用，但通常它的开销也是最昂贵的。它们昂贵的部分原因是它们必须关闭通常的略过缓存直接从写缓冲区读取数据的机制。这可能通过让一个缓冲区进行充分刷新（flush）,以及其他延迟的方式来实现。

二. java内存屏障的使用

2.1 java内存屏障使用介绍

常见的有以下几种：

a. 通过 Synchronized关键字包住的代码区域,当线程进入到该区域读取变量信息时,保证读到的是最新的值.这是因为在同步区内对变量的写入操作,在离开同步区时就将当前线程内的数据刷新到内存中,而对数据的读取也不能从缓存读取,只能从内存中读取,保证了数据的读有效性.这就是插入了StoreStore屏障
b. 使用了volatile修饰变量,则对变量的写操作,会插入StoreLoad屏障.
c. 其余的操作,则需要通过Unsafe这个类来执行.
    UNSAFE.putOrderedObject类似这样的方法,会插入StoreStore内存屏障 
    Unsafe.putVolatiObject 则是插入了StoreLoad屏障

2.2 volatile实现原理

Volatile基本介绍
Java语言规范第三版中对volatile的定义如下： java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。
Java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。
volatile作用
能保证可见性和防止指令重排序

volatile与synchronized对比
volatile变量修饰符如果使用恰当的话，它比synchronized的使用和执行成本会更低，因为它不会引起线程上下文的切换和调度


volatile如何保证可见性、防止指令重排序
volatile保持内存可见性和防止指令重排序的原理，本质上是同一个问题，也都依靠内存屏障得到解决
在x86处理器下通过工具获取JIT编译器生成的汇编指令来看看对Volatile进行写操作CPU会做什么事情。
Java代码：    instance = new Singleton();//instance是volatile变量
汇编代码：    0x01a3de1d: movb $0x0,0x1104800(%esi);0x01a3de24: lock addl $0x0,(%esp);
lock前缀指令相当于一个内存屏障（也称内存栅栏），内存屏障主要提供3个功能：
1、 确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
2、 强制将对缓存的修改操作立即写入主存，利用缓存一致性机制，并且缓存一致性机制会阻止同时修改由两个以上CPU缓存的内存区域数据；
3、如果是写操作，它会导致其他CPU中对应的缓存行无效。
一个处理器的缓存回写到内存会导致其他处理器的缓存失效。
处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。例如CPU A嗅探到CPU B打算写内存地址，且这个地址处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，
在下次访问相同内存地址时，强制执行缓存行填充。
volatile关键字通过“内存屏障”来防止指令被重排序。
为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。然而，对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，Java内存模型采取保守策略。
下面是基于保守策略的JMM内存屏障插入策略：
在每个volatile写操作的前面插入一个StoreStore屏障。
在每个volatile写操作的后面插入一个StoreLoad屏障。
在每个volatile读操作的后面插入一个LoadLoad屏障。
在每个volatile读操作的后面插入一个LoadStore屏障。
volatile为什么不能保证原子性
原子操作是一些列的操作要么全做，要么全不做，而volatile 是一种弱的同步机制，只能确保共享变量的更新操作及时被其他线程看到，以最常用的i++来说吧，包含3个步骤
1，从内存读取i当前的值 2，加1 变成 3，把修改后的值刷新到内存，volatile无法保证这三个不被打断的执行完毕，如果在刷新到内存之前有中断，此时被其他线程修改了，之前的值就无效了
volatile的适用场景
volatile是在synchronized性能低下的时候提出的。如今synchronized的效率已经大幅提升，所以volatile存在的意义不大。

